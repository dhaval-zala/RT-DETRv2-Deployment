{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openvino as ov\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import cv2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color: orange;\">**PyTorch**</span> -> <span style=\"color: #555555;\">**ONNX**</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_r18vd_120e_coco.yml\n",
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/../dataset/coco_detection_custom.yml\n",
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/../runtime.yml\n",
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/./include/dataloader.yml\n",
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/./include/optimizer.yml\n",
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/./include/rtdetrv2_r50vd.yml\n",
      "deploy/export_onnx.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(args.resume, map_location='cpu')\n",
      "Load PResNet18 state_dict\n",
      "/home/dhavalsinh/Desktop/Object_Det_n_Seg/RT-DETRv2/deploy/../rtdetrv2_pytorch/src/zoo/rtdetr/rtdetrv2_decoder.py:141: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if reference_points.shape[-1] == 2:\n",
      "/home/dhavalsinh/Desktop/Object_Det_n_Seg/RT-DETRv2/deploy/../rtdetrv2_pytorch/src/zoo/rtdetr/rtdetrv2_decoder.py:145: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  elif reference_points.shape[-1] == 4:\n",
      "Check export onnx model done...\n"
     ]
    }
   ],
   "source": [
    "!python deploy/export_onnx.py -c rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_r18vd_120e_coco.yml -r deploy/models/torchmodels/rtdetrv2_r18vd_120e_coco_rerun_48.1.pth --output_file deploy/models/onnxmodels/model.onnx --check\n",
    "\n",
    "# !python rtdetrv2_pytorch/tools/export_onnx.py -c path/to/rtdetrv2_xxx_xxx_coco.yml -r path/to/last.pth --output_file deploy/models/onnxmodels/model.onnx --check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #555555;\">**ONNX**</span> --> <span style=\"color:darkblue\">**OpenVINO**</span>   (FP32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2023_bu_IOTG_OpenVINO-2022-3&content=upg_all&medium=organic or on https://github.com/openvinotoolkit/openvino\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/dhavalsinh/Desktop/Object_Det_n_Seg/RT-DETRv2/deploy/models/openvinomodels/model.xml\n",
      "[ SUCCESS ] BIN file: /home/dhavalsinh/Desktop/Object_Det_n_Seg/RT-DETRv2/deploy/models/openvinomodels/model.bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!mo --input_model deploy/models/onnxmodels/model.onnx --output_dir deploy/models/openvinomodels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INT8 <span style=\"color:darkblue\">**OpenVINO**</span> Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installation \n",
    "# !pip install git+https://github.com/openvinotoolkit/nncf.git#egg=nncf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, onnx, openvino\n"
     ]
    }
   ],
   "source": [
    "import nncf \n",
    "from rtdetrv2_pytorch.src.core import YAMLConfig\n",
    "from rtdetrv2_pytorch.src.misc import dist_utils\n",
    "\n",
    "\n",
    "config_path = \"rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_r18vd_120e_coco.yml\"\n",
    "openvino_input_model = \"deploy/models/openvinomodels/model.xml\"\n",
    "openvino_output_model = \"deploy/models/openvinomodels/model_int8.xml\"\n",
    "update_dict = {\n",
    "    'seed': 0, 'use_amp': True, 'test_only': False, 'print_method': 'builtin', 'print_rank': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/rtdetrv2_r18vd_120e_coco.yml\n",
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/../dataset/coco_detection_custom.yml\n",
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/../runtime.yml\n",
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/./include/dataloader.yml\n",
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/./include/optimizer.yml\n",
      "Loading.... rtdetrv2_pytorch/configs/rtdetrv2/./include/rtdetrv2_r50vd.yml\n",
      "building val_dataloader with batch_size=32...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e490226759e47cc83dab1b572a08bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510a4ca72e7c43fba53e8b3d86814e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = YAMLConfig(config_path, **update_dict)\n",
    "val_dataloader = dist_utils.warp_loader(cfg.val_dataloader, \\\n",
    "            shuffle=cfg.val_dataloader.shuffle)\n",
    "\n",
    "model = ov.Core().read_model(openvino_input_model)\n",
    "compiled_model = ov.Core().compile_model(model, 'CPU')\n",
    "input_ir = model.input(0)\n",
    "N, C, H, W = input_ir.partial_shape\n",
    "W = W.get_length()\n",
    "H = H.get_length()\n",
    "\n",
    "transforms = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.Resize((W, H)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "def prepare_input_tensor(image: np.ndarray):\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = transforms(image)[None]\n",
    "    return image\n",
    "\n",
    "def transform_fn(data_item):\n",
    "    \"\"\"\n",
    "    Quantization transform function. Extracts and preprocess input data from dataloader item for quantization.\n",
    "    Parameters:\n",
    "       data_item: Tuple with data item produced by DataLoader during iteration\n",
    "    Returns:\n",
    "        input_tensor: Input data for quantization\n",
    "    \"\"\"\n",
    "    img = np.asarray(data_item[0]).astype(np.uint8)\n",
    "    input_tensor = prepare_input_tensor(img)\n",
    "    return input_tensor\n",
    "\n",
    "\n",
    "quantization_dataset = nncf.Dataset(val_dataloader, transform_fn)\n",
    "\n",
    "from openvino.runtime import serialize\n",
    "quantized_model = nncf.quantize(model, quantization_dataset, preset=nncf.QuantizationPreset.MIXED)\n",
    "serialize(quantized_model, openvino_output_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #555555;\">**ONNX**</span> -> <span style=\"color: #009B77;\">**TRT**</span> (FP16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo apt install nvidia-cudnn\n",
    "#install tensortrt 8.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "onnx_model = \"deploy/models/onnxmodels/model.onnx\"\n",
    "trt_output_model = \"deploy/models/tensorrtmodels/model.trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/06/2024-15:02:49] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[09/06/2024-15:02:49] [TRT] [W] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\n",
      "Building an engine.  This would take a while...\n",
      "(Use \"--verbose\" or \"-v\" to enable verbose logging.)\n",
      "[09/06/2024-15:02:49] [TRT] [W] Detected layernorm nodes in FP16: /model/encoder/encoder.0/layers.0/norm1/Sub, /model/encoder/encoder.0/layers.0/norm1/Pow, /model/encoder/encoder.0/layers.0/norm1/ReduceMean_1, /model/encoder/encoder.0/layers.0/norm1/Add, /model/encoder/encoder.0/layers.0/norm1/Sqrt, /model/encoder/encoder.0/layers.0/norm1/Div, /model/encoder/encoder.0/layers.0/norm1/Mul, /model/encoder/encoder.0/layers.0/norm1/Add_1, /model/encoder/encoder.0/layers.0/norm2/Sub, /model/encoder/encoder.0/layers.0/norm2/Pow, /model/encoder/encoder.0/layers.0/norm2/ReduceMean_1, /model/encoder/encoder.0/layers.0/norm2/Add, /model/encoder/encoder.0/layers.0/norm2/Sqrt, /model/encoder/encoder.0/layers.0/norm2/Div, /model/encoder/encoder.0/layers.0/norm2/Mul, /model/encoder/encoder.0/layers.0/norm2/Add_1, /model/decoder/enc_output/norm/Sub, /model/decoder/enc_output/norm/Pow, /model/decoder/enc_output/norm/ReduceMean_1, /model/decoder/enc_output/norm/Add, /model/decoder/enc_output/norm/Sqrt, /model/decoder/enc_output/norm/Div, /model/decoder/enc_output/norm/Mul, /model/decoder/enc_output/norm/Add_1, /model/decoder/decoder/layers.0/norm1/Sub, /model/decoder/decoder/layers.0/norm1/Pow, /model/decoder/decoder/layers.0/norm1/ReduceMean_1, /model/decoder/decoder/layers.0/norm1/Add, /model/decoder/decoder/layers.0/norm1/Sqrt, /model/decoder/decoder/layers.0/norm1/Div, /model/decoder/decoder/layers.0/norm1/Mul, /model/decoder/decoder/layers.0/norm1/Add_1, /model/decoder/decoder/layers.0/norm2/Sub, /model/decoder/decoder/layers.0/norm2/Pow, /model/decoder/decoder/layers.0/norm2/ReduceMean_1, /model/decoder/decoder/layers.0/norm2/Add, /model/decoder/decoder/layers.0/norm2/Sqrt, /model/decoder/decoder/layers.0/norm2/Div, /model/decoder/decoder/layers.0/norm2/Mul, /model/decoder/decoder/layers.0/norm2/Add_1, /model/decoder/decoder/layers.0/norm3/Sub, /model/decoder/decoder/layers.0/norm3/Pow, /model/decoder/decoder/layers.0/norm3/ReduceMean_1, /model/decoder/decoder/layers.0/norm3/Add, /model/decoder/decoder/layers.0/norm3/Sqrt, /model/decoder/decoder/layers.0/norm3/Div, /model/decoder/decoder/layers.0/norm3/Mul, /model/decoder/decoder/layers.0/norm3/Add_1, /model/decoder/decoder/layers.1/norm1/Sub, /model/decoder/decoder/layers.1/norm1/Pow, /model/decoder/decoder/layers.1/norm1/ReduceMean_1, /model/decoder/decoder/layers.1/norm1/Add, /model/decoder/decoder/layers.1/norm1/Sqrt, /model/decoder/decoder/layers.1/norm1/Div, /model/decoder/decoder/layers.1/norm1/Mul, /model/decoder/decoder/layers.1/norm1/Add_1, /model/decoder/decoder/layers.1/norm2/Sub, /model/decoder/decoder/layers.1/norm2/Pow, /model/decoder/decoder/layers.1/norm2/ReduceMean_1, /model/decoder/decoder/layers.1/norm2/Add, /model/decoder/decoder/layers.1/norm2/Sqrt, /model/decoder/decoder/layers.1/norm2/Div, /model/decoder/decoder/layers.1/norm2/Mul, /model/decoder/decoder/layers.1/norm2/Add_1, /model/decoder/decoder/layers.1/norm3/Sub, /model/decoder/decoder/layers.1/norm3/Pow, /model/decoder/decoder/layers.1/norm3/ReduceMean_1, /model/decoder/decoder/layers.1/norm3/Add, /model/decoder/decoder/layers.1/norm3/Sqrt, /model/decoder/decoder/layers.1/norm3/Div, /model/decoder/decoder/layers.1/norm3/Mul, /model/decoder/decoder/layers.1/norm3/Add_1, /model/decoder/decoder/layers.2/norm1/Sub, /model/decoder/decoder/layers.2/norm1/Pow, /model/decoder/decoder/layers.2/norm1/ReduceMean_1, /model/decoder/decoder/layers.2/norm1/Add, /model/decoder/decoder/layers.2/norm1/Sqrt, /model/decoder/decoder/layers.2/norm1/Div, /model/decoder/decoder/layers.2/norm1/Mul, /model/decoder/decoder/layers.2/norm1/Add_1, /model/decoder/decoder/layers.2/norm2/Sub, /model/decoder/decoder/layers.2/norm2/Pow, /model/decoder/decoder/layers.2/norm2/ReduceMean_1, /model/decoder/decoder/layers.2/norm2/Add, /model/decoder/decoder/layers.2/norm2/Sqrt, /model/decoder/decoder/layers.2/norm2/Div, /model/decoder/decoder/layers.2/norm2/Mul, /model/decoder/decoder/layers.2/norm2/Add_1, /model/decoder/decoder/layers.2/norm3/Sub, /model/decoder/decoder/layers.2/norm3/Pow, /model/decoder/decoder/layers.2/norm3/ReduceMean_1, /model/decoder/decoder/layers.2/norm3/Add, /model/decoder/decoder/layers.2/norm3/Sqrt, /model/decoder/decoder/layers.2/norm3/Div, /model/decoder/decoder/layers.2/norm3/Mul, /model/decoder/decoder/layers.2/norm3/Add_1\n",
      "[09/06/2024-15:02:49] [TRT] [W] Running layernorm after self-attention in FP16 may cause overflow. Exporting the model to the latest available ONNX opset (later than opset 17) to use the INormalizationLayer, or forcing layernorm layers to run in FP32 precision can help with preserving accuracy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10112/608488532.py:30: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/06/2024-15:05:31] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "[09/06/2024-15:05:31] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "[09/06/2024-15:05:31] [TRT] [W] Check verbose logs for the list of affected weights.\n",
      "[09/06/2024-15:05:31] [TRT] [W] - 1 weights are affected by this issue: Detected FP32 infinity values and converted them to corresponding FP16 infinity.\n",
      "[09/06/2024-15:05:31] [TRT] [W] - 140 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "[09/06/2024-15:05:31] [TRT] [W] - 17 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n",
      "[09/06/2024-15:05:31] [TRT] [W] - 4 weights are affected by this issue: Detected finite FP32 values which would overflow in FP16 and converted them to the closest finite FP16 value.\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.path.dirname(trt_output_model)\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "verbose=False\n",
    "t_dtype = trt.DataType.HALF\n",
    "network_flags = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE) if verbose else trt.Logger()\n",
    "\n",
    "with trt.Builder(TRT_LOGGER) as builder, builder.create_network(flags=network_flags) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "    with open(onnx_model, 'rb') as model:\n",
    "        if not parser.parse(model.read()):\n",
    "            print('ERROR: ONNX Parse Failed')\n",
    "            for error in range(parser.num_errors):\n",
    "                print(parser.get_error(error))\n",
    "    print('Building an engine.  This would take a while...')\n",
    "    print('(Use \"--verbose\" or \"-v\" to enable verbose logging.)')\n",
    "    config = builder.create_builder_config()\n",
    "    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 2 << 30)  # 1GB\n",
    "    profile = builder.create_optimization_profile()\n",
    "    input_name = network.get_input(0).name\n",
    "    profile.set_shape(input_name, (1, 3, 640, 640), (1, 3, 640, 640), (16, 3, 640, 640))\n",
    "    config.add_optimization_profile(profile)\n",
    "\n",
    "    # config.max_workspace_size = 2 << 30\n",
    "    if t_dtype == trt.DataType.HALF:\n",
    "        config.flags |= 1 << int(trt.BuilderFlag.FP16)\n",
    "    \n",
    "    engine = builder.build_engine(network, config)\n",
    "    \n",
    "\n",
    "    with open(trt_output_model, 'wb') as f:\n",
    "        f.write(engine.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #555555;\">**ONNX**</span> -> <span style=\"color: #009B77;\">**TRT**</span> (INT8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorrt as trt\n",
    "from deploy.calibrator import DataLoader\n",
    "\n",
    "onnx_model = \"deploy/models/onnxmodels/model.onnx\"\n",
    "trt_int8_output_model = \"deploy/models/tensorrtmodels/model_int8.trt\"\n",
    "train_path = \"path/to/train/images/folder\"\n",
    "model_input_resolution = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found all 811 images to calib.\n",
      "[09/06/2024-15:14:05] [TRT] [W] The NetworkDefinitionCreationFlag::kEXPLICIT_PRECISION flag has been deprecated and has no effect. Please do not use this flag when creating the network.\n",
      "[09/06/2024-15:14:05] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[09/06/2024-15:14:05] [TRT] [W] onnx2trt_utils.cpp:400: One or more weights outside the range of INT32 was clamped\n",
      "Building an engine.  This would take a while...\n",
      "(Use \"--verbose\" or \"-v\" to enable verbose logging.)\n",
      "trt.DataType.INT8\n",
      "Int8 calibation is enabled.\n",
      "[09/06/2024-15:14:06] [TRT] [W] Calibration Profile is not defined. Calibrating with Profile 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12289/174181261.py:46: DeprecationWarning: Use build_serialized_network instead.\n",
      "  engine = builder.build_engine(network, config)\n",
      "[ERROR] Exception caught in read_calibration_cache(): TypeError: stat: path should be string, bytes, os.PathLike or integer, not NoneType\n",
      "\n",
      "At:\n",
      "  <frozen genericpath>(20): exists\n",
      "  /home/dhavalsinh/Desktop/Object_Det_n_Seg/RT-DETRv2/deploy/calibrator.py(52): read_calibration_cache\n",
      "  /tmp/ipykernel_12289/174181261.py(46): <module>\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3505): run_code\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3445): run_ast_nodes\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3266): run_cell_async\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3061): _run_cell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3006): run_cell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py(531): run_cell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py(411): do_execute\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(729): execute_request\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(406): dispatch_shell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(499): process_one\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(510): dispatch_queue\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/asyncio/events.py(80): _run\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/asyncio/base_events.py(1922): _run_once\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/asyncio/base_events.py(607): run_forever\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py(195): start\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py(711): start\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py(992): launch_instance\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py(17): <module>\n",
      "  <frozen runpy>(88): _run_code\n",
      "  <frozen runpy>(198): _run_module_as_main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################\n",
      "['images']\n",
      "######################\n",
      "######################\n",
      "['images']\n",
      "######################\n",
      "######################\n",
      "['images']\n",
      "######################\n",
      "######################\n",
      "['images']\n",
      "######################\n",
      "######################\n",
      "['images']\n",
      "######################\n",
      "######################\n",
      "['images']\n",
      "######################\n",
      "######################\n",
      "['images']\n",
      "######################\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 138) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/encoder/encoder.0/layers.0/self_attn/Softmax_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 170) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 174) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 191) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 195) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 199) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 211) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 215) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 377) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 381) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/TopK_output_1, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/Unsqueeze_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/Expand_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/Tile_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/Expand_1_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/Tile_1_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 563) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/decoder/layers.0/self_attn/Softmax_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 595) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 599) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/decoder/layers.0/cross_attn/Softmax_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/decoder/layers.0/cross_attn/Reshape_3_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 700) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 840) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 843) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 915) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 919) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 946) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 950) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 982) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 983) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 988) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 991) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 992) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1075) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/decoder/layers.1/self_attn/Softmax_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1107) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1111) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/decoder/layers.1/cross_attn/Softmax_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/decoder/layers.1/cross_attn/Reshape_3_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1209) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1346) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1349) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1421) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1425) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1452) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1456) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1488) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1489) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1494) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1497) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1498) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1581) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/decoder/layers.2/self_attn/Softmax_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1613) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1617) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/decoder/layers.2/cross_attn/Softmax_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor /model/decoder/decoder/layers.2/cross_attn/Reshape_3_output_0, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1715) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1852) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1855) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1927) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1931) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1958) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1962) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1994) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 1995) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 2000) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 2003) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 2004) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Missing scale and zero-point for tensor (Unnamed Layer* 2033) [Constant]_output, expect fall back to non-int8 implementation for any layer consuming or producing given tensor\n",
      "[09/06/2024-15:14:16] [TRT] [W] Detected layernorm nodes in FP16: /model/encoder/encoder.0/layers.0/norm1/Sub, /model/encoder/encoder.0/layers.0/norm1/Pow, /model/encoder/encoder.0/layers.0/norm1/ReduceMean_1, /model/encoder/encoder.0/layers.0/norm1/Add, /model/encoder/encoder.0/layers.0/norm1/Sqrt, /model/encoder/encoder.0/layers.0/norm1/Div, /model/encoder/encoder.0/layers.0/norm1/Mul, /model/encoder/encoder.0/layers.0/norm1/Add_1, /model/encoder/encoder.0/layers.0/norm2/Sub, /model/encoder/encoder.0/layers.0/norm2/Pow, /model/encoder/encoder.0/layers.0/norm2/ReduceMean_1, /model/encoder/encoder.0/layers.0/norm2/Add, /model/encoder/encoder.0/layers.0/norm2/Sqrt, /model/encoder/encoder.0/layers.0/norm2/Div, /model/encoder/encoder.0/layers.0/norm2/Mul, /model/encoder/encoder.0/layers.0/norm2/Add_1, /model/decoder/enc_output/norm/Sub, /model/decoder/enc_output/norm/Pow, /model/decoder/enc_output/norm/ReduceMean_1, /model/decoder/enc_output/norm/Add, /model/decoder/enc_output/norm/Sqrt, /model/decoder/enc_output/norm/Div, /model/decoder/enc_output/norm/Mul, /model/decoder/enc_output/norm/Add_1, /model/decoder/decoder/layers.0/norm1/Sub, /model/decoder/decoder/layers.0/norm1/Pow, /model/decoder/decoder/layers.0/norm1/ReduceMean_1, /model/decoder/decoder/layers.0/norm1/Add, /model/decoder/decoder/layers.0/norm1/Sqrt, /model/decoder/decoder/layers.0/norm1/Div, /model/decoder/decoder/layers.0/norm1/Mul, /model/decoder/decoder/layers.0/norm1/Add_1, /model/decoder/decoder/layers.0/norm2/Sub, /model/decoder/decoder/layers.0/norm2/Pow, /model/decoder/decoder/layers.0/norm2/ReduceMean_1, /model/decoder/decoder/layers.0/norm2/Add, /model/decoder/decoder/layers.0/norm2/Sqrt, /model/decoder/decoder/layers.0/norm2/Div, /model/decoder/decoder/layers.0/norm2/Mul, /model/decoder/decoder/layers.0/norm2/Add_1, /model/decoder/decoder/layers.0/norm3/Sub, /model/decoder/decoder/layers.0/norm3/Pow, /model/decoder/decoder/layers.0/norm3/ReduceMean_1, /model/decoder/decoder/layers.0/norm3/Add, /model/decoder/decoder/layers.0/norm3/Sqrt, /model/decoder/decoder/layers.0/norm3/Div, /model/decoder/decoder/layers.0/norm3/Mul, /model/decoder/decoder/layers.0/norm3/Add_1, /model/decoder/decoder/layers.1/norm1/Sub, /model/decoder/decoder/layers.1/norm1/Pow, /model/decoder/decoder/layers.1/norm1/ReduceMean_1, /model/decoder/decoder/layers.1/norm1/Add, /model/decoder/decoder/layers.1/norm1/Sqrt, /model/decoder/decoder/layers.1/norm1/Div, /model/decoder/decoder/layers.1/norm1/Mul, /model/decoder/decoder/layers.1/norm1/Add_1, /model/decoder/decoder/layers.1/norm2/Sub, /model/decoder/decoder/layers.1/norm2/Pow, /model/decoder/decoder/layers.1/norm2/ReduceMean_1, /model/decoder/decoder/layers.1/norm2/Add, /model/decoder/decoder/layers.1/norm2/Sqrt, /model/decoder/decoder/layers.1/norm2/Div, /model/decoder/decoder/layers.1/norm2/Mul, /model/decoder/decoder/layers.1/norm2/Add_1, /model/decoder/decoder/layers.1/norm3/Sub, /model/decoder/decoder/layers.1/norm3/Pow, /model/decoder/decoder/layers.1/norm3/ReduceMean_1, /model/decoder/decoder/layers.1/norm3/Add, /model/decoder/decoder/layers.1/norm3/Sqrt, /model/decoder/decoder/layers.1/norm3/Div, /model/decoder/decoder/layers.1/norm3/Mul, /model/decoder/decoder/layers.1/norm3/Add_1, /model/decoder/decoder/layers.2/norm1/Sub, /model/decoder/decoder/layers.2/norm1/Pow, /model/decoder/decoder/layers.2/norm1/ReduceMean_1, /model/decoder/decoder/layers.2/norm1/Add, /model/decoder/decoder/layers.2/norm1/Sqrt, /model/decoder/decoder/layers.2/norm1/Div, /model/decoder/decoder/layers.2/norm1/Mul, /model/decoder/decoder/layers.2/norm1/Add_1, /model/decoder/decoder/layers.2/norm2/Sub, /model/decoder/decoder/layers.2/norm2/Pow, /model/decoder/decoder/layers.2/norm2/ReduceMean_1, /model/decoder/decoder/layers.2/norm2/Add, /model/decoder/decoder/layers.2/norm2/Sqrt, /model/decoder/decoder/layers.2/norm2/Div, /model/decoder/decoder/layers.2/norm2/Mul, /model/decoder/decoder/layers.2/norm2/Add_1, /model/decoder/decoder/layers.2/norm3/Sub, /model/decoder/decoder/layers.2/norm3/Pow, /model/decoder/decoder/layers.2/norm3/ReduceMean_1, /model/decoder/decoder/layers.2/norm3/Add, /model/decoder/decoder/layers.2/norm3/Sqrt, /model/decoder/decoder/layers.2/norm3/Div, /model/decoder/decoder/layers.2/norm3/Mul, /model/decoder/decoder/layers.2/norm3/Add_1\n",
      "[09/06/2024-15:14:16] [TRT] [W] Running layernorm after self-attention in FP16 may cause overflow. Exporting the model to the latest available ONNX opset (later than opset 17) to use the INormalizationLayer, or forcing layernorm layers to run in FP32 precision can help with preserving accuracy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] Exception caught in read_calibration_cache(): TypeError: stat: path should be string, bytes, os.PathLike or integer, not NoneType\n",
      "\n",
      "At:\n",
      "  <frozen genericpath>(20): exists\n",
      "  /home/dhavalsinh/Desktop/Object_Det_n_Seg/RT-DETRv2/deploy/calibrator.py(52): read_calibration_cache\n",
      "  /tmp/ipykernel_12289/174181261.py(46): <module>\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3505): run_code\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3445): run_ast_nodes\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3266): run_cell_async\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3061): _run_cell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3006): run_cell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py(531): run_cell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py(411): do_execute\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(729): execute_request\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(406): dispatch_shell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(499): process_one\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(510): dispatch_queue\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/asyncio/events.py(80): _run\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/asyncio/base_events.py(1922): _run_once\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/asyncio/base_events.py(607): run_forever\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py(195): start\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py(711): start\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py(992): launch_instance\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py(17): <module>\n",
      "  <frozen runpy>(88): _run_code\n",
      "  <frozen runpy>(198): _run_module_as_main\n",
      "\n",
      "[ERROR] Exception caught in write_calibration_cache(): TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "\n",
      "At:\n",
      "  /home/dhavalsinh/Desktop/Object_Det_n_Seg/RT-DETRv2/deploy/calibrator.py(58): write_calibration_cache\n",
      "  /tmp/ipykernel_12289/174181261.py(46): <module>\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3505): run_code\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3445): run_ast_nodes\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3266): run_cell_async\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3061): _run_cell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py(3006): run_cell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py(531): run_cell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py(411): do_execute\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(729): execute_request\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(406): dispatch_shell\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(499): process_one\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py(510): dispatch_queue\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/asyncio/events.py(80): _run\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/asyncio/base_events.py(1922): _run_once\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/asyncio/base_events.py(607): run_forever\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py(195): start\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py(711): start\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py(992): launch_instance\n",
      "  /home/dhavalsinh/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py(17): <module>\n",
      "  <frozen runpy>(88): _run_code\n",
      "  <frozen runpy>(198): _run_module_as_main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/06/2024-15:23:00] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "[09/06/2024-15:23:00] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "[09/06/2024-15:23:00] [TRT] [W] Check verbose logs for the list of affected weights.\n",
      "[09/06/2024-15:23:00] [TRT] [W] - 1 weights are affected by this issue: Detected FP32 infinity values and converted them to corresponding FP16 infinity.\n",
      "[09/06/2024-15:23:00] [TRT] [W] - 140 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "[09/06/2024-15:23:00] [TRT] [W] - 17 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n",
      "[09/06/2024-15:23:00] [TRT] [W] - 4 weights are affected by this issue: Detected finite FP32 values which would overflow in FP16 and converted them to the closest finite FP16 value.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder_path = os.path.dirname(trt_int8_output_model)\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "\n",
    "verbose=False\n",
    "calib_loader = DataLoader(32, 6, train_path,\n",
    "                                  model_input_resolution, model_input_resolution)\n",
    "int8_calib = True\n",
    "calib_cache = None\n",
    "t_dtype = trt.DataType.INT8\n",
    "network_flags = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "if t_dtype == trt.DataType.INT8:\n",
    "    network_flags = network_flags | (1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_PRECISION))\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE) if verbose else trt.Logger()\n",
    "\n",
    "with trt.Builder(TRT_LOGGER) as builder, builder.create_network(flags=network_flags) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "    with open(onnx_model, 'rb') as model:\n",
    "        if not parser.parse(model.read()):\n",
    "            print('ERROR: ONNX Parse Failed')\n",
    "            for error in range(parser.num_errors):\n",
    "                print(parser.get_error(error))\n",
    "    print('Building an engine.  This would take a while...')\n",
    "    print('(Use \"--verbose\" or \"-v\" to enable verbose logging.)')\n",
    "    config = builder.create_builder_config()\n",
    "    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 2 << 30)  # 1GB\n",
    "    profile = builder.create_optimization_profile()\n",
    "    input_name = network.get_input(0).name\n",
    "    profile.set_shape(input_name, (1, 3, 640, 640), (1, 3, 640, 640), (16, 3, 640, 640))\n",
    "    config.add_optimization_profile(profile)\n",
    "\n",
    "    # config.max_workspace_size = 2 << 30\n",
    "    if t_dtype == trt.DataType.HALF:\n",
    "        config.flags |= 1 << int(trt.BuilderFlag.FP16)\n",
    "    if t_dtype == trt.DataType.INT8:\n",
    "        print('trt.DataType.INT8')\n",
    "        config.flags |= 1 << int(trt.BuilderFlag.INT8)\n",
    "        config.flags |= 1 << int(trt.BuilderFlag.FP16)\n",
    "\n",
    "        if int8_calib:\n",
    "            from deploy.calibrator import Calibrator\n",
    "            config.int8_calibrator = Calibrator(calib_loader, calib_cache)\n",
    "            print('Int8 calibation is enabled.')\n",
    "    \n",
    "    engine = builder.build_engine(network, config)\n",
    "    # print(engine)\n",
    "\n",
    "    with open(trt_int8_output_model, 'wb') as f:\n",
    "        f.write(engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
